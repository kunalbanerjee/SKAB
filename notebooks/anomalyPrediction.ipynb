{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f84320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Kunal Banerjee'\n",
    "__date__ = '20231012'\n",
    "__email__ = 'kunal.banerjee1@walmart.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf1199",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7542a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                            mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2aa85",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e35fd97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7ab5e",
   "metadata": {},
   "source": [
    "## Preprocess the data for classification and regression tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3610226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(filename, retainDatetime=False, applyRegressionOnDroppingEdge=False):\n",
    "    print('Prepocessing ', filename)\n",
    "    data = pd.read_csv(filename, sep=';')\n",
    "    #print(data.columns)\n",
    "    \n",
    "    if retainDatetime == False:\n",
    "        data = data.drop(['datetime'], axis=1)\n",
    "        \n",
    "    data_label = data['anomaly']\n",
    "    data_label_regr = data_label.copy()\n",
    "    # Find the indices of the changepoints\n",
    "    index_cp = data[data['changepoint'] == 1].index\n",
    "    \n",
    "    if len(index_cp) != 4 and len(index_cp) != 2:\n",
    "        print('ERROR:: Unexpected number of changepoints ', len(index_cp), ' detected in ', filename)\n",
    "        exit()\n",
    "        \n",
    "    if len(index_cp) == 2:\n",
    "        print('Abrupt anomalies detected in ', filename)\n",
    "    else:\n",
    "        data_label[index_cp[0]:index_cp[1]] = 0\n",
    "        data_label[index_cp[2]:index_cp[3]] = 0\n",
    "        \n",
    "        for i in range(index_cp[0], index_cp[1]):\n",
    "            data_label_regr.loc[i] = (i - index_cp[0] + 1)/(index_cp[1] - index_cp[0] + 1)\n",
    "        if applyRegressionOnDroppingEdge:\n",
    "            for i in range(index_cp[2], index_cp[3]):\n",
    "                # For the dropping edge, the target value for regression should be monotonically decreasing\n",
    "                data_label_regr.loc[i] = 1.0 - ((i - index_cp[2] + 1)/(index_cp[3] - index_cp[2] + 1))\n",
    "                \n",
    "    # Drop the target variables\n",
    "    data = data.drop(['anomaly', 'changepoint'], axis=1)\n",
    "    \n",
    "    return data, data_label, data_label_regr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b2168",
   "metadata": {},
   "source": [
    "## Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3bac4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(train, train_label, test, test_label, algorithm='xgb'):\n",
    "    # create model instance\n",
    "    if algorithm == 'xgb':\n",
    "        classifier = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "    elif algorithm == 'svm':\n",
    "        classifier = SVC(kernel='linear')\n",
    "    elif algorithm == 'gaussiannb':\n",
    "        classifier = GaussianNB()\n",
    "    else:\n",
    "        print('ERROR:: Unknown classification algorithm: ', algorithm)\n",
    "        exit()\n",
    "    # fit model\n",
    "    classifier.fit(train, train_label)\n",
    "    # make predictions\n",
    "    preds = classifier.predict(test)\n",
    "    return classifier, accuracy_score(test_label, preds), balanced_accuracy_score(test_label, preds), \\\n",
    "           f1_score(test_label, preds), precision_score(test_label, preds), recall_score(test_label, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f0b2a",
   "metadata": {},
   "source": [
    "## Perform regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "185ef683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(train, train_label, test, test_label, algorithm='xgb'):\n",
    "    # create model instance\n",
    "    if algorithm == 'xgb':\n",
    "        regressor = XGBRegressor(objective ='reg:squarederror', n_estimators = 10, seed = 123)\n",
    "    elif algorithm == 'svm':\n",
    "        regressor = SVR(kernel='rbf')\n",
    "    elif algorithm == 'lasso':\n",
    "        regressor = Lasso(alpha=0.1)\n",
    "    elif algorithm == 'ridge':\n",
    "        regressor = Ridge(alpha=0.1)\n",
    "    else:\n",
    "        print('ERROR:: Unknown regression algorithm: ', algorithm)\n",
    "        exit()\n",
    "    # fit model\n",
    "    regressor.fit(train, train_label)\n",
    "    # make predictions\n",
    "    preds = regressor.predict(test)\n",
    "    rmse = mean_squared_error(test_label, preds, squared=True)\n",
    "    return regressor, rmse\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0a90a",
   "metadata": {},
   "source": [
    "## Perform anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c91183a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_prediction(data, classifier, regressor):\n",
    "    preds = list()\n",
    "    for row in data:\n",
    "        row = row.reshape(1,-1)\n",
    "        pred = classifier.predict(row)\n",
    "        if pred != 1:\n",
    "            pred = regressor.predict(row)\n",
    "        \n",
    "        preds.append(pred)\n",
    "        \n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e890c3",
   "metadata": {},
   "source": [
    "## Evaluate anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d2786c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_anomaly_prediction(test_label_regr, preds, threshold):\n",
    "    # Expecting the test label to contain values between 0 and 1, i.e., it's same as test_label_regr\n",
    "    for i in range(len(test_label_regr)):\n",
    "        if test_label_regr[i] != 0:\n",
    "            test_label_regr.loc[i] = 1\n",
    "    \n",
    "    # We need to create a copy so that the original preds does not get modified\n",
    "    predsCopy = list()\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] >= threshold:\n",
    "            predsCopy.append(1)\n",
    "        else:\n",
    "            predsCopy.append(0)\n",
    "            \n",
    "    return accuracy_score(test_label_regr, predsCopy), balanced_accuracy_score(test_label_regr, predsCopy), \\\n",
    "           f1_score(test_label_regr, predsCopy), precision_score(test_label_regr, predsCopy), \\\n",
    "           recall_score(test_label_regr, predsCopy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23564c34",
   "metadata": {},
   "source": [
    "## Code for training and testing anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe9f403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    # Create the list of files to be used for training\n",
    "    trainFiles = list()\n",
    "    for i in range(3):\n",
    "        filename = PATH_TO_DATA + 'valve2/' + str(i) + '.csv'\n",
    "        trainFiles.append(filename)\n",
    "    \n",
    "    print('Files used for training: ', trainFiles)\n",
    "    \n",
    "    # Create the list of files to be used for testing\n",
    "    testFiles = list()\n",
    "    for i in range(3,4):\n",
    "        filename = PATH_TO_DATA + 'valve2/' + str(i) + '.csv'\n",
    "        testFiles.append(filename)\n",
    "        \n",
    "    print('Files used for testing: ', testFiles)\n",
    "    \n",
    "    # We don't need to retain datetime for classifiers such as XGBClassifier\n",
    "    retainDatetime=False\n",
    "    \n",
    "    columns = ['Accelerometer1RMS', 'Accelerometer2RMS', 'Current', 'Pressure', 'Temperature', \n",
    "               'Thermocouple', 'Voltage', 'Volume Flow RateRMS']\n",
    "    if retainDatetime:\n",
    "        columns = columns.insert(0, 'datetime')\n",
    "\n",
    "    train = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    train_label = pd.Series(dtype=np.float64)\n",
    "    train_label_regr = pd.Series(dtype=np.float64)\n",
    "    for file in trainFiles:\n",
    "        data, data_label, data_label_regr = preprocess_data(file)\n",
    "        train = pd.concat([train, data], ignore_index=True)\n",
    "        train_label = pd.concat([train_label, data_label], ignore_index=True)\n",
    "        train_label_regr = pd.concat([train_label_regr, data_label_regr], ignore_index=True)\n",
    "        \n",
    "    test = pd.DataFrame(columns=columns)\n",
    "    test_label = pd.Series(dtype=np.float64)\n",
    "    test_label_regr = pd.Series(dtype=np.float64)\n",
    "    for file in testFiles:\n",
    "        data, data_label, data_label_regr = preprocess_data(file)\n",
    "        test = pd.concat([test, data], ignore_index=True)\n",
    "        test_label = pd.concat([test_label, data_label], ignore_index=True)\n",
    "        test_label_regr = pd.concat([test_label_regr, data_label_regr], ignore_index=True)\n",
    "    \n",
    "    # Scale the data\n",
    "    # Note that due to scaling, pandas.DataFrame becomes numpy.ndarray\n",
    "    scaler = StandardScaler()\n",
    "    if retainDatetime == False:\n",
    "        scaler.fit(train)\n",
    "        train = scaler.transform(train)\n",
    "        test = scaler.transform(test)\n",
    "    else:\n",
    "        cols_to_scale = columns\n",
    "        cols_to_scale.remove('datetime')\n",
    "        scaler.fit(train[cols_to_scale])\n",
    "        train[cols_to_scale] = scaler.transform(train[cols_to_scale])\n",
    "        test[cols_to_scale] = scaler.transform(test[cols_to_scale])\n",
    "    \n",
    "    classifier, accuracy, balanced_accuracy, f1, precision, recall = \\\n",
    "        classification(train, train_label, test, test_label, algorithm='gaussiannb')\n",
    "    print('Classification:: Accuracy: ', accuracy, ' Balanced Accuracy: ', balanced_accuracy, \n",
    "          ' F1: ', f1, ' Precision: ', precision, ' Recall: ', recall)\n",
    "    \n",
    "    # Plot feature importance of classifier\n",
    "    #plot_importance(classifier)\n",
    "    #plt.show()\n",
    "    \n",
    "    regressor, rmse = regression(train, train_label_regr, test, test_label_regr, algorithm='ridge')\n",
    "    print('Regression:: RMSE: ', rmse)\n",
    "    \n",
    "    preds = anomaly_prediction(test, classifier, regressor)\n",
    "    print('Anomaly Prediction')\n",
    "    for threshold in np.arange(0.5, 1.0, 0.1):\n",
    "        APaccuracy, APbalanced_accuracy, APf1, APprecision, APrecall = \\\n",
    "            evaluate_anomaly_prediction(test_label_regr, preds, threshold)\n",
    "        print('Threshold:: ', threshold, ' Accuracy: ', APaccuracy, ' Balanced Accuracy: ', APbalanced_accuracy, \n",
    "              ' F1: ', APf1, ' Precision: ', APprecision, ' Recall: ', APrecall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
